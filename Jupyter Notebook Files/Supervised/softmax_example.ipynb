{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: Softmax\n",
    "Austin Ahlstrom<br>\n",
    "Dr. Jarvis<br>\n",
    "Math 402 Sec 001<br>\n",
    "6 Dec 2018 (Thu)<br>\n",
    "Volume III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.datasets.fashion_mnist as f_mnist\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential \n",
    "import keras.utils.np_utils as np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the newton-cg solver, there were 61 mistakes out of 1258 data points.\n",
      "Using the sag solver, there were 71 mistakes out of 1258 data points.\n",
      "Using the lbfgs solver, there were 65 mistakes out of 1258 data points.\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits['data'], digits['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.70,\n",
    "        random_state=1)\n",
    "for solver in ['newton-cg', 'sag', 'lbfgs']:\n",
    "    clf = LogisticRegression(random_state=1, solver=solver,\n",
    "            multi_class='multinomial').fit(x_train, y_train)\n",
    "    mistakes = len(y_test[clf.predict(x_test) != y_test])\n",
    "    print('Using the', solver, 'solver, there were', mistakes, 'mistakes',\n",
    "         'out of', len(y_test), 'data points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All regularization solving methods yielded similar levels of errors in classifications. The newton-cg solver yielded the least in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took a lot of effort, but Keras and TensorFlow are now installed on my computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 5us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 5s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = f_mnist.load_data()\n",
    "input_dim = 784 #28*28\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "output_dim = 10\n",
    "soft = Sequential()\n",
    "soft.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "soft.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With batch size of 4 and epoch count of 10: 14.506288906097414\n",
      "With batch size of 4 and epoch count of 20: 14.506288907445272\n",
      "With batch size of 4 and epoch count of 30: 14.506288905385336\n",
      "With batch size of 4 and epoch count of 40: 14.506288904774985\n",
      "With batch size of 4 and epoch count of 50: 14.506288914515176\n",
      "With batch size of 8 and epoch count of 10: 14.506288907928468\n",
      "With batch size of 8 and epoch count of 20: 14.506288909149168\n",
      "With batch size of 8 and epoch count of 30: 14.506288911972044\n",
      "With batch size of 8 and epoch count of 40: 14.506288912556968\n",
      "With batch size of 8 and epoch count of 50: 14.506288907190958\n",
      "With batch size of 16 and epoch count of 10: 14.506288913421633\n",
      "With batch size of 16 and epoch count of 20: 14.506288909327191\n",
      "With batch size of 16 and epoch count of 30: 14.506288910853067\n",
      "With batch size of 16 and epoch count of 40: 14.506288906046553\n",
      "With batch size of 16 and epoch count of 50: 14.50628890586853\n",
      "With batch size of 32 and epoch count of 10: 14.506288908004763\n",
      "With batch size of 32 and epoch count of 20: 14.506288909301759\n",
      "With batch size of 32 and epoch count of 30: 14.506288908462526\n",
      "With batch size of 32 and epoch count of 40: 14.50628890530904\n",
      "With batch size of 32 and epoch count of 50: 14.506288906758627\n",
      "With batch size of 64 and epoch count of 10: 14.506288912531534\n",
      "With batch size of 64 and epoch count of 20: 14.506288906784059\n",
      "With batch size of 64 and epoch count of 30: 14.506288909047445\n",
      "With batch size of 64 and epoch count of 40: 14.506288909835817\n",
      "With batch size of 64 and epoch count of 50: 14.506288905461627\n",
      "With batch size of 128 and epoch count of 10: 14.506288905614218\n",
      "With batch size of 128 and epoch count of 20: 14.506288911234535\n",
      "With batch size of 128 and epoch count of 30: 14.506288904444379\n",
      "With batch size of 128 and epoch count of 40: 14.506288909657794\n",
      "With batch size of 128 and epoch count of 50: 14.506288907546997\n",
      "With batch size of 256 and epoch count of 10: 14.506288905588784\n",
      "With batch size of 256 and epoch count of 20: 14.50628890591939\n",
      "With batch size of 256 and epoch count of 30: 14.506288908843993\n",
      "With batch size of 256 and epoch count of 40: 14.506288907801311\n",
      "With batch size of 256 and epoch count of 50: 14.506288909098311\n",
      "With batch size of 512 and epoch count of 10: 14.506288913040162\n",
      "With batch size of 512 and epoch count of 20: 14.506288907012939\n",
      "With batch size of 512 and epoch count of 30: 14.506288904393514\n",
      "With batch size of 512 and epoch count of 40: 14.506288903274532\n",
      "With batch size of 512 and epoch count of 50: 14.50628890701294\n",
      "With batch size of 1024 and epoch count of 10: 14.50628890457153\n",
      "With batch size of 1024 and epoch count of 20: 14.506288903706865\n",
      "With batch size of 1024 and epoch count of 30: 14.506288908869426\n",
      "With batch size of 1024 and epoch count of 40: 14.506288910598752\n",
      "With batch size of 1024 and epoch count of 50: 14.50628891202291\n"
     ]
    }
   ],
   "source": [
    "histories = {}\n",
    "batch_sizes, epoch_counts = 2**np.array(range(2,11)), 10*np.array(range(1,6))\n",
    "for b_size in batch_sizes:\n",
    "    for e_count in epoch_counts:\n",
    "        print('With batch size of', b_size, 'and epoch count of',\n",
    "                str(e_count) + ': ', end='')\n",
    "        history = soft.fit(X_train, Y_train, batch_size=128, epochs=20,\n",
    "                verbose=0, validation_data=(X_test, Y_test))\n",
    "        print(np.mean(history.history['loss']))\n",
    "        histories[(b_size, e_count)] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
